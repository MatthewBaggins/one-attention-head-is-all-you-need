{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PBe5K-JpHXFs"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Sorting Fixed Length Lists with One Head"
      ],
      "metadata": {
        "id": "jKyC3mZ72qlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variable hyperparameters"
      ],
      "metadata": {
        "id": "PBe5K-JpHXFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed length of list to be sorted\n",
        "LIST_LENGTH = 10\n",
        "\n",
        "# Size of vocabulary\n",
        "D_VOCAB = 66\n",
        "\n",
        "# Should lists have repetitions?\n",
        "ALLOW_REPETITIONS = False\n",
        "\n",
        "# Attention only? (False -> model includes MLPs)\n",
        "ATTN_ONLY = False\n",
        "\n",
        "# Model dimensions\n",
        "N_LAYERS = 1\n",
        "N_HEADS = 1\n",
        "D_MODEL = 128\n",
        "D_HEAD = 32\n",
        "D_MLP = 32\n",
        "\n",
        "if ATTN_ONLY:\n",
        "    D_MLP = None\n",
        "\n",
        "# Default batch size\n",
        "DEFAULT_BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "httbkgCwHYF4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prelude"
      ],
      "metadata": {
        "id": "7o--LiD_HMGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install and import"
      ],
      "metadata": {
        "id": "7yjVSLZbEEJX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Wqa5uVY-2oC7"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import transformer_lens\n",
        "except:\n",
        "    !pip install git+https://github.com/neelnanda-io/TransformerLens\n",
        "    !pip install circuitsvis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "from dataclasses import dataclass, field\n",
        "from datetime import datetime as dt\n",
        "from itertools import repeat\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "from typing import cast, Generator, Literal\n",
        "\n",
        "import circuitsvis as cv\n",
        "from fancy_einsum import einsum\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, tensor, Tensor, TensorType as TT\n",
        "from torch.nn import functional as F\n",
        "from transformer_lens import HookedTransformerConfig, HookedTransformer\n",
        "from tqdm import tqdm\n",
        "from typing_extensions import Self\n",
        "\n",
        "cv.examples.hello(\"You\")"
      ],
      "metadata": {
        "id": "dqFfW5V32yaO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "ef6f200d-ea25-4164-acdd-b0ccd98c26c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x7f063c823310>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-0a0671ee-8605\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, Hello } from \"https://unpkg.com/circuitsvis@1.38.1/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-0a0671ee-8605\",\n",
              "      Hello,\n",
              "      {\"name\": \"You\"}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Invariable hyperparameters"
      ],
      "metadata": {
        "id": "Oo4oP4dSrYhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"{DEVICE = }\")\n",
        "\n",
        "# Seeds to generate training, validation, and test data\n",
        "TRAIN_SEED = 42\n",
        "VAL_SEED = 66\n",
        "TEST_SEED = 1729\n",
        "\n",
        "# Context length: [start, *(unsorted_)list_length, mid, *(sorted_)list_length]\n",
        "N_CTX = 2 * LIST_LENGTH + 2\n",
        "\n",
        "# \"Real\" tokens range from 0 to D_VOCAB - 2 (non-inclusive)\n",
        "VOCAB_MIN_ID = 0\n",
        "VOCAB_MAX_ID = D_VOCAB - 2\n",
        "\n",
        "# START token is D_VOCAB - 2 and MID token is D_VOCAB - 1\n",
        "START_TOKEN_ID = VOCAB_MAX_ID\n",
        "MID_TOKEN_ID = D_VOCAB - 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XwivtyM_Hru",
        "outputId": "956d1292-6d98-4255-c14a-98f84921ed60"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE = 'cpu'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data generator and datasets"
      ],
      "metadata": {
        "id": "dlWGwox63j24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_list(batch_size: int) -> Tensor:\n",
        "    if ALLOW_REPETITIONS:\n",
        "        return torch.randint(VOCAB_MIN_ID, VOCAB_MAX_ID, (batch_size, LIST_LENGTH))\n",
        "    return tensor([\n",
        "        random.sample(range(VOCAB_MIN_ID, VOCAB_MAX_ID), k=LIST_LENGTH) \n",
        "        for _ in range(batch_size)\n",
        "    ]).to(DEVICE)\n",
        "\n",
        "# General generator\n",
        "def make_data_gen(\n",
        "    *,\n",
        "    batch_size: int = DEFAULT_BATCH_SIZE,\n",
        "    dataset: Literal[\"train\", \"val\", \"test\"], # probably this arg needs a better name,\n",
        ") -> Generator[Tensor, None, None]:\n",
        "    assert dataset in (\"train\", \"val\", \"test\")\n",
        "    if dataset == \"train\":\n",
        "        seed = TRAIN_SEED\n",
        "    elif dataset == \"val\":\n",
        "        seed = VAL_SEED\n",
        "    else: # test\n",
        "        seed = TEST_SEED\n",
        "    torch.manual_seed(seed)\n",
        "    while True:\n",
        "        # Generate random numbers\n",
        "        x = generate_list(batch_size)\n",
        "        # Sort\n",
        "        x_sorted = torch.sort(x, dim=1).values\n",
        "        # START tokens\n",
        "        x_start = START_TOKEN_ID * torch.ones(batch_size, dtype=torch.int32).reshape(batch_size, -1).to(DEVICE)\n",
        "        # MID tokens\n",
        "        x_mid = MID_TOKEN_ID * torch.ones(batch_size, dtype=torch.int32).reshape(batch_size, -1).to(DEVICE)\n",
        "        yield torch.cat((x_start, x, x_mid, x_sorted), dim=1)\n",
        "\n",
        "\n",
        "# Training data generator (kinda wrapper)\n",
        "def make_train_gen() -> Generator[Tensor, None, None]:\n",
        "    \"\"\"Make generator of training data\"\"\"\n",
        "    return make_data_gen(batch_size=128, dataset=\"train\")\n",
        "\n",
        "# Validation and test data\n",
        "\n",
        "val_data = next(make_data_gen(batch_size=1000, dataset=\"val\"))\n",
        "test_data = next(make_data_gen(batch_size=1000, dataset=\"test\"))"
      ],
      "metadata": {
        "id": "44OZjOq83k1H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss function"
      ],
      "metadata": {
        "id": "hBJn1fKm3pMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(\n",
        "    logits: Tensor, # [batch, pos, d_vocab] \n",
        "    tokens: Tensor, # [batch, pos] \n",
        "    return_per_token: bool = False\n",
        ") -> Tensor: # scalar\n",
        "    \"\"\"\"\"\"\n",
        "    # \n",
        "    sorted_start_pos = LIST_LENGTH + 2\n",
        "    logits = logits[:, (sorted_start_pos-1):-1]\n",
        "    tokens = tokens[:, sorted_start_pos : None]\n",
        "    log_probs = logits.log_softmax(-1)\n",
        "    correct_log_probs = log_probs.gather(-1, tokens[..., None])[..., 0]\n",
        "    if return_per_token:\n",
        "        return -correct_log_probs\n",
        "    return -correct_log_probs.mean()"
      ],
      "metadata": {
        "id": "PTlNfaKY3qkd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy and validation"
      ],
      "metadata": {
        "id": "GKKrzLEq3sun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_diff_row_inds(\n",
        "    a: Tensor, # [dim1, dim2]\n",
        "    b: Tensor  # [dim1, dim2]\n",
        ") -> Tensor:   # [dim1]\n",
        "    \"\"\"Find indices of rows where a and b differ\"\"\"\n",
        "    assert a.shape == b.shape\n",
        "    return ((a == b).prod(dim=1) == 0).nonzero(as_tuple=True)[0]\n",
        "\n",
        "def acc_fn(\n",
        "    logits: Tensor, # [batch, pos, d_vocab]\n",
        "    tokens: Tensor, # [batch, pos]\n",
        "    per: Literal[\"token\", \"sequence\"] = \"sequence\"\n",
        ") -> float:\n",
        "    \"\"\"Compute accuracy as percentage of correct predictions\"\"\"\n",
        "    sorted_start_pos = LIST_LENGTH + 2\n",
        "    # Get logits of predictions for position\n",
        "    logits = logits[:, (sorted_start_pos-1):-1]\n",
        "    preds = logits.argmax(-1)\n",
        "    tokens = tokens[:, sorted_start_pos:]\n",
        "    if per == \"sequence\":\n",
        "        return (preds == tokens).prod(dim=1).float().mean().item()\n",
        "    return (preds == tokens).float().mean().item()\n",
        "\n",
        "def validate(\n",
        "    model: HookedTransformer, \n",
        "    data: Tensor # [batch, pos]\n",
        ") -> float:\n",
        "    \"\"\"Test this model on `data`\"\"\"\n",
        "    logits = model(data)\n",
        "    acc = acc_fn(logits, tokens=data)\n",
        "    return acc\n",
        "\n",
        "def show_mispreds(\n",
        "    model: HookedTransformer, \n",
        "    data: Tensor # [batch, pos]\n",
        ") -> None:\n",
        "    \"\"\"Test this model on `data` and print mispredictions\"\"\"\n",
        "    logits = model(data)\n",
        "    sorted_start_pos = LIST_LENGTH + 2\n",
        "    logits = logits[:, (sorted_start_pos-1):-1]\n",
        "    tokens = data[:, sorted_start_pos:]\n",
        "    preds = logits.argmax(-1)\n",
        "    mispred_inds = get_diff_row_inds(tokens, preds)\n",
        "    for i in mispred_inds:\n",
        "        print(f\"[{i}] {tokens[i].numpy().tolist()} | {preds[i].numpy().tolist()}\")\n",
        "    print(f\"{len(mispred_inds)}/{len(preds)} ({len(mispred_inds) / len(preds) :.2%})\")"
      ],
      "metadata": {
        "id": "1x6q7b7O3rZa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "V5trW5nKhF3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "32Hj7N1nhHrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = HookedTransformerConfig(\n",
        "    d_model=D_MODEL,\n",
        "    n_layers=N_LAYERS,\n",
        "    n_heads=N_HEADS,\n",
        "    d_head=D_HEAD,\n",
        "    n_ctx=N_CTX,\n",
        "    d_vocab=D_VOCAB,\n",
        "    act_fn=\"relu\",\n",
        "    seed=42,\n",
        "    device=DEVICE,\n",
        "    attn_only=ATTN_ONLY\n",
        ")\n",
        "model = HookedTransformer(cfg, move_to_device=True)"
      ],
      "metadata": {
        "id": "YwIffvImhT4g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training setup"
      ],
      "metadata": {
        "id": "9vYV7QAd3vCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass(frozen=True)\n",
        "class TrainingHistory:\n",
        "    losses: list[float]\n",
        "    train_accuracies: list[float]\n",
        "    val_accuracies: list[float]\n",
        "\n",
        "def converged(val_accs: list[float], n_last: int = 2) -> bool:\n",
        "    if len(val_accs) < n_last:\n",
        "        return False\n",
        "    return len(set(tensor(val_accs[-n_last:]).round(decimals=4).tolist())) == 1\n",
        "\n",
        "# Number of epochs\n",
        "n_epochs = 20000\n",
        "\n",
        "# Optimization\n",
        "lr = 1e-3\n",
        "betas = (.9, .999)\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=lr, betas=betas)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, \"min\", patience=100)\n",
        "\n",
        "# Training data generator\n",
        "train_gen = make_train_gen()\n",
        "\n",
        "def train_model(model: HookedTransformer) -> TrainingHistory:\n",
        "    losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        tokens = next(train_gen).to(device=DEVICE)\n",
        "        logits = model(tokens)\n",
        "        loss = loss_fn(logits, tokens)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        scheduler.step(loss)\n",
        "        \n",
        "        if epoch % 100 == 0:\n",
        "            losses.append(loss.item())\n",
        "            train_batch_acc = acc_fn(logits, tokens)\n",
        "            val_acc = validate(model, val_data)\n",
        "            val_loss = loss_fn(model(val_data), val_data)\n",
        "\n",
        "            train_accuracies.append(train_batch_acc)\n",
        "            val_accuracies.append(val_acc)\n",
        "            print(\n",
        "                f\"Epoch {epoch}/{n_epochs} ({epoch / n_epochs:.0%}) : \"\n",
        "                f\"loss = {loss.item():.4f}; {train_batch_acc=:.3%}; \"\n",
        "                f\"{val_acc=:.3%}; lr={scheduler._last_lr[0]}\" #type:ignore\n",
        "            )\n",
        "            # If last 10 recorded val_accuracies are 100%\n",
        "            if converged(val_accuracies):\n",
        "                print(f\"\\nAchieved consistent perfect validation accuracy after {epoch} epochs\")\n",
        "                break\n",
        "    return TrainingHistory(losses, train_accuracies, val_accuracies)\n",
        "\n",
        "def load_model_state(model: HookedTransformer, filename: str) -> None:\n",
        "    assert os.path.isdir(\"models\"), \"Make a directory `models` with model state dicts\"\n",
        "    if not filename.startswith(\"models/\"):\n",
        "        filename = f\"models/{filename}\"\n",
        "    with open(filename, \"rb\") as f:\n",
        "        state_dict = pickle.load(f)\n",
        "    model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "LHBPL3Xw3uAt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train or load model"
      ],
      "metadata": {
        "id": "HXhR2JBjdXkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model)\n",
        "# load_model_state(model, <filename>)"
      ],
      "metadata": {
        "id": "CMH8DwNHdWLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f1cc520-bcda-44a8-c0dd-93b5727d0136"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/20000 (0%) : loss = 4.4698; train_batch_acc=0.000%; val_acc=0.000%; lr=0.001\n",
            "Epoch 100/20000 (0%) : loss = 0.1413; train_batch_acc=75.781%; val_acc=72.300%; lr=0.001\n",
            "Epoch 200/20000 (1%) : loss = 0.0188; train_batch_acc=99.219%; val_acc=96.800%; lr=0.001\n",
            "Epoch 300/20000 (2%) : loss = 0.0131; train_batch_acc=98.438%; val_acc=98.700%; lr=0.001\n",
            "Epoch 400/20000 (2%) : loss = 0.0081; train_batch_acc=99.219%; val_acc=99.000%; lr=0.001\n",
            "Epoch 500/20000 (2%) : loss = 0.0081; train_batch_acc=97.656%; val_acc=99.400%; lr=0.001\n",
            "Epoch 600/20000 (3%) : loss = 0.0023; train_batch_acc=100.000%; val_acc=99.500%; lr=0.001\n",
            "Epoch 700/20000 (4%) : loss = 0.0032; train_batch_acc=100.000%; val_acc=99.500%; lr=0.001\n",
            "\n",
            "Achieved consistent perfect validation accuracy after 700 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing post-training"
      ],
      "metadata": {
        "id": "HABWttcH34dv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Validating on validation data:\")\n",
        "val_acc = validate(model, val_data)\n",
        "print(f\"\\t{val_acc=:.3%}\\n\")\n",
        "if val_acc < 1:\n",
        "    show_mispreds(model, val_data)\n",
        "\n",
        "print(\"\\nValidating on test data:\")\n",
        "test_acc = validate(model, test_data)\n",
        "print(f\"\\t{test_acc=:.3%}\\n\")\n",
        "if test_acc < 1:\n",
        "    show_mispreds(model, test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lakshPyuwdO7",
        "outputId": "c7f14878-2871-4194-bbb6-45206c7f6232"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating on validation data:\n",
            "\tval_acc=99.500%\n",
            "\n",
            "[88] [2, 36, 39, 42, 43, 44, 47, 48, 53, 58] | [2, 35, 39, 42, 43, 44, 47, 48, 53, 58]\n",
            "[137] [3, 26, 29, 30, 35, 37, 44, 47, 62, 63] | [3, 29, 29, 30, 35, 37, 44, 47, 62, 63]\n",
            "[346] [4, 7, 9, 16, 19, 50, 51, 61, 62, 63] | [4, 7, 9, 16, 19, 51, 51, 61, 62, 63]\n",
            "[545] [1, 3, 4, 9, 50, 51, 52, 53, 56, 57] | [1, 3, 4, 9, 38, 51, 52, 53, 56, 57]\n",
            "[716] [1, 6, 16, 23, 29, 32, 60, 61, 62, 63] | [1, 6, 16, 23, 29, 32, 61, 61, 62, 63]\n",
            "5/1000 (0.50%)\n",
            "\n",
            "Validating on test data:\n",
            "\ttest_acc=99.700%\n",
            "\n",
            "[522] [0, 6, 9, 13, 18, 25, 27, 59, 61, 62] | [0, 6, 9, 13, 18, 25, 27, 61, 61, 62]\n",
            "[613] [5, 7, 10, 11, 50, 51, 55, 56, 58, 63] | [5, 7, 10, 11, 43, 51, 55, 56, 58, 63]\n",
            "[957] [1, 3, 10, 12, 45, 48, 49, 50, 53, 56] | [1, 3, 10, 12, 48, 48, 49, 50, 53, 56]\n",
            "3/1000 (0.30%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving trained model"
      ],
      "metadata": {
        "id": "pNofXtfSQvh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model_state_dict(\n",
        "    model: HookedTransformer, \n",
        "    filename: str | None = None\n",
        ") -> None:\n",
        "    if not os.path.isdir(\"models\"):\n",
        "        os.mkdir(\"models\")\n",
        "    if not filename:\n",
        "        timestamp = dt.now().isoformat(\"T\", \"minutes\").replace(\":\", \"-\")\n",
        "        filename = f\"model_state_dict_{timestamp}.pkl\"\n",
        "    with open(f\"models/{filename}\", \"wb\") as f:\n",
        "        pickle.dump(model.state_dict(), f)\n",
        "\n",
        "save_model_state_dict(model)"
      ],
      "metadata": {
        "id": "i9lLO9p1d8mC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"models\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpp4UQG9ql_u",
        "outputId": "4ee66d44-52ce-4378-f1e1-0454780bea48"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_state_dict_2023-01-22T21-31.pkl',\n",
              " 'model_state_dict_2023-01-22T21-52.pkl',\n",
              " 'model_state_dict_2023-01-22T21-24.pkl',\n",
              " 'model_state_dict_2023-01-22T21-09.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Investigate the model"
      ],
      "metadata": {
        "id": "Nnfh-Oxk7sQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention patterns"
      ],
      "metadata": {
        "id": "S7po8YMfN4T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get one input from test_data\n",
        "test_input = test_data[3, :]\n",
        "\n",
        "# Pass through model, get cache and predictions\n",
        "logits, cache_model = model.run_with_cache(test_input, remove_batch_dim=True) \n",
        "preds = logits[:, LIST_LENGTH+1 : -1].argmax(-1)\n",
        "\n",
        "# Get attention pattern and plot it\n",
        "attention_pattern = cache_model[\"pattern\", 0, \"attn\"]\n",
        "tokens_input = list(map(str, test_input))\n",
        "print(test_input)\n",
        "print(preds)\n",
        "\n",
        "cv.attention.attention_patterns(tokens=tokens_input, attention=attention_pattern)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "kPODH527Rc5h",
        "outputId": "a8646e55-b1ca-4743-c8e2-90edade082ff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([64,  7, 61, 23, 37,  2, 22, 43, 32, 39,  5, 65,  2,  5,  7, 22, 23, 32,\n",
            "        37, 39, 43, 61])\n",
            "tensor([[ 2,  5,  7, 22, 23, 32, 37, 39, 43, 61]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x7f063d083850>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-8e3bdb15-f0f6\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.38.1/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-8e3bdb15-f0f6\",\n",
              "      AttentionPatterns,\n",
              "      {\"tokens\": [\"tensor(64)\", \"tensor(7)\", \"tensor(61)\", \"tensor(23)\", \"tensor(37)\", \"tensor(2)\", \"tensor(22)\", \"tensor(43)\", \"tensor(32)\", \"tensor(39)\", \"tensor(5)\", \"tensor(65)\", \"tensor(2)\", \"tensor(5)\", \"tensor(7)\", \"tensor(22)\", \"tensor(23)\", \"tensor(32)\", \"tensor(37)\", \"tensor(39)\", \"tensor(43)\", \"tensor(61)\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49830442667007446, 0.5016955733299255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.449179083108902, 0.1733180284500122, 0.377502977848053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5586269497871399, 0.035255853086709976, 0.144239142537117, 0.26187798380851746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014545475132763386, 0.03698878735303879, 0.609351634979248, 0.05512243136763573, 0.2839916944503784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02677248790860176, 0.9134721755981445, 0.005711066070944071, 0.011501922272145748, 0.007842684164643288, 0.03469964116811752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06963755190372467, 0.030486153438687325, 0.0030228719115257263, 0.762901782989502, 0.06563092023134232, 0.010752991773188114, 0.05756768211722374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027931781485676765, 0.0026738138403743505, 0.740749716758728, 0.014401779510080814, 0.011144664138555527, 0.08607082068920135, 0.007484686095267534, 0.10954280197620392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005910172592848539, 0.0018397117964923382, 0.0559786856174469, 0.0007373039843514562, 0.5571615695953369, 0.010627011768519878, 0.004349566996097565, 0.33964675664901733, 0.023749271407723427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006395877338945866, 0.03626001253724098, 0.07189816981554031, 0.002036023186519742, 0.006584166083484888, 0.4852781891822815, 0.001112437923438847, 0.3678813576698303, 0.0017920753452926874, 0.0207616426050663, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005761223146691918, 0.9302764534950256, 0.0002863994159270078, 0.009709342382848263, 0.0021227761171758175, 0.022593270987272263, 0.017423193901777267, 0.00025060155894607306, 0.0019177100621163845, 0.0026387053076177835, 0.01220546942204237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.175563663011417e-05, 0.10119559615850449, 2.649210910021793e-05, 0.0008364150999113917, 0.00011730733240256086, 0.7010970115661621, 0.0013977013295516372, 4.0951523260446265e-05, 6.37138364254497e-05, 0.0001495646283729002, 0.19494706392288208, 8.643968612886965e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004593410529196262, 0.3709898591041565, 0.00028240136452950537, 0.01680649258196354, 0.0030588950030505657, 0.007381487172096968, 0.02455451898276806, 0.0005151909426786005, 0.0011941655538976192, 0.0018496611155569553, 0.5631717443466187, 0.004419436678290367, 0.0011826585978269577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0022567403502762318, 0.8207761645317078, 0.0002224210911663249, 0.05148959904909134, 0.009140470996499062, 0.009129040874540806, 0.057169653475284576, 0.001633825828321278, 0.01261300127953291, 0.007583308033645153, 0.017253050580620766, 0.007547442801296711, 0.0008007804863154888, 0.0023844637908041477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04010377824306488, 0.03311454877257347, 0.0027285341639071703, 0.290516197681427, 0.06538461893796921, 0.00193273916374892, 0.4145451784133911, 0.015808390453457832, 0.10121531039476395, 0.006376638077199459, 0.01973511092364788, 0.005380572751164436, 0.0001665003946982324, 0.0010493284789845347, 0.0019425422651693225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014013636857271194, 0.0039140088483691216, 0.0007504750974476337, 0.5344632267951965, 0.10169676691293716, 0.0007063106750138104, 0.026367872953414917, 0.05359497666358948, 0.2001638412475586, 0.06277546286582947, 0.00017824819951783866, 0.0006427898770198226, 5.0788232329068705e-05, 1.8788708985084668e-05, 8.392591553274542e-05, 0.00057890301104635, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027227697893977165, 0.0022180003579705954, 0.0019332951633259654, 0.0383090116083622, 0.19440028071403503, 0.0002048640453722328, 0.04070916399359703, 0.14216695725917816, 0.3456510901451111, 0.20419292151927948, 0.0001532447204226628, 0.0009681315859779716, 3.043658762180712e-05, 1.3968256098451093e-05, 4.4980988604947925e-05, 0.0005652459803968668, 0.0012107070069760084, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002283570123836398, 0.00019245504518039525, 0.011463446542620659, 0.0008459006203338504, 0.437656968832016, 0.0005355747998692095, 0.003186020767316222, 0.20179736614227295, 0.02438231185078621, 0.31621649861335754, 1.3671875422005542e-05, 0.00046781942364759743, 9.379089169669896e-05, 2.622567762955441e-06, 9.98875384539133e-06, 0.00010217642557108775, 2.1357478544814512e-05, 0.0007284747553057969, 0.0, 0.0, 0.0, 0.0], [0.00021875175298191607, 0.0004977171192876995, 0.011454462073743343, 0.001748085836879909, 0.020413726568222046, 0.0011922894045710564, 0.0013551837764680386, 0.49015599489212036, 0.0036243554204702377, 0.4680235683917999, 5.8136225561611354e-05, 0.00028306679450906813, 0.000131270891870372, 1.0847421435755678e-05, 2.8050655600964092e-05, 7.951806037453935e-05, 4.288904892746359e-05, 3.0483681257464923e-05, 0.0006517082802020013, 0.0, 0.0, 0.0], [0.0013379832962527871, 0.00021621824998874217, 0.04899943619966507, 0.0005814165342599154, 0.018639415502548218, 0.0024738602805882692, 0.0002265865623485297, 0.8867100477218628, 0.0020964047871530056, 0.032633695751428604, 5.2952767873648554e-05, 0.0033229957334697247, 0.0009756837971508503, 4.406443622428924e-05, 2.949725603684783e-05, 2.0048484657309018e-05, 1.5152699234022293e-05, 2.2523239749716595e-05, 0.00029265685589052737, 0.0013092925073578954, 0.0, 0.0], [0.0007621146505698562, 1.717769555398263e-05, 0.9557870030403137, 0.00012300550588406622, 0.002148138824850321, 0.0009443674935027957, 0.00020412397861946374, 0.034798089414834976, 0.0002927861351054162, 0.0029083990957587957, 0.00022058079775888473, 0.0003067433135583997, 0.0005126319592818618, 0.00013079003838356584, 9.162336027657147e-06, 5.655569111695513e-05, 5.44171734873089e-06, 3.059856908294023e-06, 1.5129437997529749e-05, 2.006470640480984e-05, 0.0007345698541030288, 0.0], [0.013718442060053349, 0.004347211681306362, 0.023722853511571884, 0.006231766194105148, 0.008545419201254845, 0.07599146664142609, 0.006031978875398636, 0.005445763003081083, 0.002866563154384494, 0.008422432467341423, 0.23151496052742004, 0.01018188614398241, 0.10485799610614777, 0.42339813709259033, 0.016327399760484695, 0.014992915093898773, 0.010456136427819729, 0.0034436783753335476, 0.007029472850263119, 0.006574935745447874, 0.0021673617884516716, 0.01373105775564909]]]}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FWbRRSo8Xnxz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}